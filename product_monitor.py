# -*- coding: utf-8 -*-
import os
import time
import json
import requests
import concurrent.futures
import threading
from datetime import datetime
from base_login import BaseLogin
from detail_processor import DetailProcessor
from wechat_bot import WeChatBot

COOLDOWN_DAYS = 3.5
COOLDOWN_FILE = 'cooldown_state.json'

class ProductMonitor(BaseLogin):
    def __init__(self):
        super().__init__()
        self.BASE_DIR = os.path.dirname(os.path.abspath(__file__))
        self.initial_data_file = os.path.join(self.BASE_DIR, 'initial_products_data.json')
        self.output_file = os.path.join(self.BASE_DIR, 'products_output.txt')
        self.counter_state_file = os.path.join(self.BASE_DIR, 'daily_counter.json')
        self.cooldown_file = os.path.join(self.BASE_DIR, COOLDOWN_FILE)

        self.detail_processor = DetailProcessor()
        self.wechat_bot = WeChatBot()
        self.products_data = self.load_initial_data()

        self.current_date = datetime.now().strftime('%Y-%m-%d')
        self.product_counter = self._load_or_init_daily_counter()

        self.max_workers = 8

        self.cooldown_days = float(COOLDOWN_DAYS)  # ä½¿ç”¨æµ®ç‚¹æ•°ä¿æŒ3.5å¤©
        self.cooldown_seconds = self.cooldown_days * 86400
        self.cooldown_map = self._load_cooldown_map()  # { "article_size": last_ts }
        
        # ä¸ºæ¯ä¸ªç¾¤ç»´æŠ¤ç‹¬ç«‹çš„è®¡æ•°å™¨
        self.counter_group_1 = self._load_or_init_group_counter(1)  # â‰¤2
        self.counter_group_2 = self._load_or_init_group_counter(2)  # 3â‰¤5
        self.counter_group_3 = self._load_or_init_group_counter(3)  # â‰¥6
        
        # æ¨é€é”ï¼Œé˜²æ­¢å¹¶å‘é‡å¤æ¨é€
        self.push_lock = threading.Lock()
        # æ­£åœ¨æ¨é€çš„å•†å“é›†åˆï¼Œé˜²æ­¢é‡å¤æ¨é€
        self.pushing_products = set()
        # è®¡æ•°å™¨é”ï¼Œé˜²æ­¢å¹¶å‘æ—¶è®¡æ•°å™¨å†²çª
        self.counter_lock = threading.Lock()
        
        # è¿ç»­å¤±è´¥è®¡æ•°å™¨ï¼Œç”¨äºæ£€æµ‹ç™»å½•è¿‡æœŸ
        self.consecutive_failures = 0
        self.max_failures_before_relogin = 3  # è¿ç»­å¤±è´¥3æ¬¡åé‡æ–°ç™»å½•
        # ä¸Šæ¬¡ç™»å½•æ—¶é—´
        self.last_login_time = None
        # ç™»å½•æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰ï¼Œè®¾ä¸º1å°æ—¶ï¼Œè¶…è¿‡åˆ™ä¸»åŠ¨åˆ·æ–°
        self.login_refresh_interval = 3600

    # ====== ç®€æ˜“ I/O ======
    def _fast_write_json(self, path: str, obj):
        path = os.path.abspath(path)
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(obj, f, ensure_ascii=False, indent=2)
            f.flush()
            os.fsync(f.fileno())

    def _load_or_init_daily_counter(self):
        today = self.current_date
        if os.path.exists(self.counter_state_file):
            try:
                with open(self.counter_state_file, 'r', encoding='utf-8') as f:
                    st = json.load(f)
                if st.get('date') == today and isinstance(st.get('counter'), int) and st['counter'] >= 1:
                    return st['counter']
            except Exception:
                pass
        self._save_daily_counter(1)
        return 1

    def _save_daily_counter(self, value=None):
        if value is not None:
            self.product_counter = value
        # ä¿ç•™ç°æœ‰çš„ç¾¤ç»„è®¡æ•°å™¨æ•°æ®ï¼Œé¿å…è¦†ç›–
        if os.path.exists(self.counter_state_file):
            try:
                with open(self.counter_state_file, 'r', encoding='utf-8') as f:
                    state = json.load(f)
            except Exception:
                state = {}
        else:
            state = {}
        state['date'] = self.current_date
        state['counter'] = self.product_counter
        try:
            self._fast_write_json(self.counter_state_file, state)
        except Exception as e:
            print(f"[warn] å†™å…¥ {os.path.basename(self.counter_state_file)} å¤±è´¥ï¼š{e}")

    def _load_or_init_group_counter(self, group_num: int):
        """åŠ è½½æˆ–åˆå§‹åŒ–ç¾¤ç»„è®¡æ•°å™¨"""
        today = self.current_date
        if os.path.exists(self.counter_state_file):
            try:
                with open(self.counter_state_file, 'r', encoding='utf-8') as f:
                    st = json.load(f)
                group_key = f'counter_group_{group_num}'
                if st.get('date') == today and isinstance(st.get(group_key), int) and st[group_key] >= 1:
                    return st[group_key]
            except Exception:
                pass
        self._save_group_counter(group_num, 1)
        return 1

    def _save_group_counter(self, group_num: int, value: int):
        """ä¿å­˜ç¾¤ç»„è®¡æ•°å™¨"""
        today = self.current_date
        if os.path.exists(self.counter_state_file):
            try:
                with open(self.counter_state_file, 'r', encoding='utf-8') as f:
                    st = json.load(f)
            except Exception:
                st = {'date': today}
        else:
            st = {'date': today}
        
        st['date'] = today
        st[f'counter_group_{group_num}'] = value
        
        try:
            self._fast_write_json(self.counter_state_file, st)
        except Exception as e:
            print(f"[warn] å†™å…¥ç¾¤ç»„è®¡æ•°å™¨å¤±è´¥ï¼š{e}")

    def _rollover_if_new_day(self):
        today = datetime.now().strftime('%Y-%m-%d')
        if today != self.current_date:
            print(f"[æ—¥æœŸåˆ‡æ¢] {self.current_date} â†’ {today}ï¼Œé‡ç½®æ‰€æœ‰è®¡æ•°å™¨")
            self.current_date = today
            # é‡ç½®æ‰€æœ‰è®¡æ•°å™¨ä¸º1
            self.product_counter = 1
            self.counter_group_1 = 1
            self.counter_group_2 = 1
            self.counter_group_3 = 1
            # ä¿å­˜åˆ°æ–‡ä»¶
            state = {
                'date': today,
                'counter': 1,
                'counter_group_1': 1,
                'counter_group_2': 1,
                'counter_group_3': 1
            }
            try:
                self._fast_write_json(self.counter_state_file, state)
            except Exception as e:
                print(f"[warn] é‡ç½®è®¡æ•°å™¨å¤±è´¥ï¼š{e}")

    # ====== ä¸šåŠ¡ I/O ======
    def load_initial_data(self):
        if os.path.exists(self.initial_data_file):
            try:
                with open(self.initial_data_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"[warn] è¯»å– {os.path.basename(self.initial_data_file)} å¤±è´¥ï¼š{e}")
                return []
        return []

    def save_initial_data(self):
        try:
            self._fast_write_json(self.initial_data_file, self.products_data)
        except Exception as e:
            print(f"[warn] å†™å…¥ {os.path.basename(self.initial_data_file)} å¤±è´¥ï¼š{e}")

    def write_to_output_file(self, content):
        try:
            with open(self.output_file, 'a', encoding='utf-8') as f:
                f.write(content + '\n' + '=' * 80 + '\n\n')
        except Exception as e:
            print(f"[warn] å†™å…¥ {os.path.basename(self.output_file)} å¤±è´¥ï¼š{e}")

    # ====== å†·å´ï¼ˆæŒ‰å°ºç ï¼‰ ======
    def _cool_key_size(self, article_num: str, size: str, fallback_id: str) -> str:
        """ç”Ÿæˆå†·å´keyï¼šè´§å·_å°ºç """
        base = (article_num or "").strip()
        if base:
            return f"{base}_{size}"
        return f"{fallback_id}_{size}"

    def _is_cooled_size(self, key: str) -> bool:
        ts = self.cooldown_map.get(key)
        if not isinstance(ts, (int, float)):
            return False
        return (time.time() - float(ts)) < self.cooldown_seconds

    def _mark_cooled_size(self, key: str):
        self.cooldown_map[key] = time.time()
        self._save_cooldown_map()

    def _cooldown_remaining_seconds(self, key: str) -> int:
        ts = self.cooldown_map.get(key)
        if not isinstance(ts, (int, float)):
            return 0
        elapsed = time.time() - float(ts)
        rem = int(self.cooldown_seconds - elapsed)
        return rem if rem > 0 else 0

    def _fmt_hms(self, seconds: int) -> str:
        h = seconds // 3600
        m = (seconds % 3600) // 60
        s = seconds % 60
        return f"{h:02d}:{m:02d}:{s:02d}"

    def _load_cooldown_map(self):
        if os.path.exists(self.cooldown_file):
            try:
                with open(self.cooldown_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"[warn] è¯»å– {os.path.basename(self.cooldown_file)} å¤±è´¥ï¼š{e}")
                return {}
        return {}

    def _save_cooldown_map(self):
        try:
            self._fast_write_json(self.cooldown_file, self.cooldown_map)
        except Exception as e:
            print(f"[warn] å†™å…¥ {os.path.basename(self.cooldown_file)} å¤±è´¥ï¼š{e}")

    # ===== ç™»å½•åˆ·æ–° =====
    def _should_refresh_login(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°ç™»å½•ï¼ˆè¶…è¿‡1å°æ—¶æˆ–è¿ç»­å¤±è´¥å¤šæ¬¡ï¼‰"""
        if self.last_login_time is None:
            return False
        elapsed = time.time() - self.last_login_time
        return elapsed > self.login_refresh_interval
    
    def _try_relogin(self):
        """å°è¯•é‡æ–°ç™»å½•"""
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ğŸ”„ æ­£åœ¨å°è¯•é‡æ–°ç™»å½•...")
        if self.login_with_captcha(self.detail_processor):
            self.consecutive_failures = 0
            self.last_login_time = time.time()
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] âœ“ é‡æ–°ç™»å½•æˆåŠŸ")
            return True
        else:
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] âœ— é‡æ–°ç™»å½•å¤±è´¥")
            return False

    # ===== åˆ—è¡¨ =====
    def fetch_page(self, page_num, page_size=500):
        data = {'pageSize': str(page_size), 'pageNum': str(page_num),
                'orderByColumn': 'updateTime', 'isAsc': 'desc'}
        try:
            r = requests.post('https://www.gxkj123456.com/tgc/gxPc/seek/list',
                              cookies=self.cookies, headers=self.headers, data=data, timeout=10)
            if r.status_code != 200:
                print(f"[debug] fetch_page çŠ¶æ€ç å¼‚å¸¸: {r.status_code}")
                return None
            result = r.json()
            if result.get('code') != 0:
                print(f"[debug] fetch_page è¿”å›ç å¼‚å¸¸: code={result.get('code')}, msg={result.get('msg', '')}")
                return None
            return result.get('rows', [])
        except Exception as e:
            print(f"[debug] fetch_page å¼‚å¸¸: {e}")
            return None

    def detect_changes(self, new_products):
        new_items, updated_items, unchanged_items = [], [], []
        existing_ids = {p['id']: p for p in self.products_data}
        for product in new_products:
            pid = product['id']
            if pid not in existing_ids:
                new_items.append(product)
                product['size_price_counts'] = {}
                product['full_size_price_counts'] = {}
                product['last_checked'] = datetime.now().isoformat()
                self.products_data.append(product)
            else:
                old = existing_ids[pid]
                if product.get('updateTime') != old.get('updateTime'):
                    updated_items.append({'old': old, 'new': product})
                    old.update(product)
                    old['last_checked'] = datetime.now().isoformat()
                else:
                    unchanged_items.append(product)
        return new_items, updated_items, unchanged_items

    def _find_or_attach_ref(self, product):
        for p in self.products_data:
            if p['id'] == product['id']:
                return p
        self.products_data.append(product)
        return product

    def process_products_streaming(self, products, change_type):
        if not products:
            return

        id_to_ref = {p['id']: self._find_or_attach_ref(p) for p in products}

        processed = 0
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as ex:
            future_to_id = {ex.submit(self.detail_processor.fetch_and_process_detail, p): p['id'] for p in products}
            for fut in concurrent.futures.as_completed(future_to_id):
                pid = future_to_id[fut]
                target = id_to_ref.get(pid)
                if not target:
                    continue

                try:
                    detail_result = fut.result()
                except Exception as e:
                    print(f"[detail error] product {pid}: {e}")
                    continue
                if not detail_result:
                    continue

                article_num = detail_result.get('article_num', '') or target.get('articleNum', '') or ''
                curr_full = detail_result.get('size_price_counts_full', {}) or {}
                kept_map = detail_result.get('size_price_counts', {}) or {}  # ç™½åå• + äººæ•°>0 + (ä»·åœ¨åŒºé—´æˆ–=0)
                kept_all = sorted(list(kept_map.keys()), key=self.detail_processor._size_sort_key)

                # â€”â€” è€å¿«ç…§ â€”â€” #
                old_full_snapshot = target.get('full_size_price_counts', {}) or {}
                old_kept_sizes = target.get('kept_sizes', []) or []
                history_view = {'full_size_price_counts': old_full_snapshot, 'kept_sizes': old_kept_sizes}

                # ===== æ–°å¢æ£€æµ‹ï¼ˆæ—§=0 â†’ æ–°>0ï¼‰ï¼Œéœ€æ’é™¤å†·å´ä¸­çš„å°ºç  =====
                def old0_newpos(s) -> bool:
                    old_c = int((old_full_snapshot.get(s) or {}).get('count', 0) or 0)
                    new_c = int((curr_full.get(s) or {}).get('count', 0) or 0)
                    return (s in kept_map) and (old_c <= 0 and new_c > 0)
                
                def is_size_cooled(s) -> bool:
                    """æ£€æŸ¥å°ºç æ˜¯å¦åœ¨å†·å´æœŸ"""
                    size_key = self._cool_key_size(article_num, s, fallback_id=str(pid))
                    return self._is_cooled_size(size_key)

                # æ’é™¤å†·å´ä¸­çš„å°ºç 
                newly_added_kept = [s for s in kept_all if old0_newpos(s) and not is_size_cooled(s)]
                has_new_size_order = len(newly_added_kept) > 0

                # ===== è·å–æ‰€æœ‰è¦æ˜¾ç¤ºçš„å°ºç ï¼ˆåŒ…æ‹¬ä»·æ ¼è¶…è¿‡èŒƒå›´çš„ï¼‰ =====
                # æ‰€æœ‰å…è®¸çš„å°ºç ï¼ˆç”¨äºæ˜¾ç¤ºå’Œè®¡ç®—ç¾¤ç»„ï¼‰
                all_allowed_sizes = sorted(
                    [s for s in curr_full.keys() if self.detail_processor._size_allowed(s)],
                    key=self.detail_processor._size_sort_key
                )
                
                # ===== æŒ‰å°ºç æ£€æŸ¥å†·å´å’Œç­›é€‰éœ€è¦æ¨é€çš„å°ºç  =====
                # å¯¹äº kept_map ä¸­çš„å°ºç ï¼Œæ£€æŸ¥å†·å´
                push_sizes_kept = []
                for s in kept_all:
                    size_key = self._cool_key_size(article_num, s, fallback_id=str(pid))
                    if not self._is_cooled_size(size_key):
                        push_sizes_kept.append(s)
                    else:
                        rem = self._cooldown_remaining_seconds(size_key)
                        if rem > 0:
                            print(f"  â³ å†·å´ä¸­ï¼ˆè´§å·={article_num} å°ºç ={s}ï¼‰ï¼šå‰©ä½™ {self._fmt_hms(rem)}")
                
                # å¯¹äºä¸åœ¨ kept_map ä¸­çš„å°ºç ï¼ˆä»·æ ¼è¶…è¿‡èŒƒå›´ï¼‰ï¼Œä¸æ£€æŸ¥å†·å´ï¼Œç›´æ¥è®¡å…¥
                push_sizes_other = [s for s in all_allowed_sizes if s not in kept_all]
                
                # åˆå¹¶æ‰€æœ‰è¦æ¨é€çš„å°ºç 
                push_sizes = push_sizes_kept + push_sizes_other

                # ===== æ˜¯å¦æ¨é€ =====
                need_push = False
                # åªåœ¨ä»¥ä¸‹æƒ…å†µæ¨é€ï¼š
                # 1. æ–°å¢å•†å“ä¸”æœ‰æœªå†·å´çš„ç¬¦åˆæ¡ä»¶çš„å°ºç 
                # 2. æœ‰å°ºç çš„è®¢å•æ•°ä»0å˜ä¸º>0ï¼ˆ0â†’æ­£æ•°ï¼‰ä¸”æœªå†·å´
                if change_type.startswith('ğŸ†•') and push_sizes_kept:
                    # æ–°å¢å•†å“ä¹Ÿæ£€æŸ¥å†·å´ï¼Œåªæœ‰æœªå†·å´çš„å°ºç æ‰æ¨é€
                    need_push = True
                elif has_new_size_order:
                    need_push = True
                # æ³¨æ„ï¼šä¸å†å› ä¸º"æœ‰æœªå†·å´çš„å°ºç "å°±æ¨é€ï¼Œé¿å…æ— å˜åŒ–æ—¶é‡å¤æ¨é€

                # æœªè§¦å‘ï¼šä»…æ›´æ–°å†å²
                if not need_push:
                    target['detail_data'] = detail_result
                    target['size_price_counts'] = kept_map
                    target['full_size_price_counts'] = curr_full
                    self.detail_processor.update_product_history(target, target['size_price_counts'], curr_full)
                    self.save_initial_data()
                    continue

                # è§¦å‘æ¨é€ï¼šåªæ¨é€æœªå†·å´çš„å°ºç ï¼ˆkept_mapä¸­çš„ï¼‰
                filtered_kept_map = {s: kept_map[s] for s in push_sizes_kept if s in kept_map}
                detail_for_output = dict(detail_result)
                detail_for_output['size_price_counts'] = filtered_kept_map
                detail_for_output['size_price_counts_full'] = curr_full

                # æ ¹æ®æ‰€æœ‰è¦æ˜¾ç¤ºçš„å°ºç æ•°é‡ç¡®å®šç¾¤ç»„å’Œè®¡æ•°å™¨ï¼ˆåŒ…æ‹¬ä»·æ ¼è¶…è¿‡èŒƒå›´å’Œå†·å´ä¸­çš„ï¼‰
                # ä½¿ç”¨ all_allowed_sizes è€Œä¸æ˜¯ push_sizesï¼Œå› ä¸ºç¾¤ç»„åˆ†é…åº”è¯¥åŸºäºæ‰€æœ‰æ˜¾ç¤ºçš„å°ºç 
                size_count = len(all_allowed_sizes)
                
                # ä½¿ç”¨é”ä¿æŠ¤è®¡æ•°å™¨æ“ä½œï¼Œé˜²æ­¢å¹¶å‘å†²çª
                with self.counter_lock:
                    if size_count <= 2:
                        group_num = 1
                        next_no = self.counter_group_1
                        self.counter_group_1 += 1
                        self._save_group_counter(1, self.counter_group_1)
                    elif size_count <= 5:
                        group_num = 2
                        next_no = self.counter_group_2
                        self.counter_group_2 += 1
                        self._save_group_counter(2, self.counter_group_2)
                    else:  # >= 6
                        group_num = 3
                        next_no = self.counter_group_3
                        self.counter_group_3 += 1
                        self._save_group_counter(3, self.counter_group_3)

                formatted_output, img_url = self.detail_processor.format_product_output(
                    target, detail_for_output, history_view, next_no, change_type, group_num
                )

                if formatted_output:
                    # ä½¿ç”¨æ¨é€é”å’Œé›†åˆé˜²æ­¢é‡å¤æ¨é€
                    # ä½¿ç”¨ pid ä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œè€Œä¸æ˜¯ next_noï¼ˆå› ä¸º next_no å¯èƒ½ä¸åŒï¼‰
                    push_key = f"{article_num}_{pid}" if article_num else str(pid)
                    with self.push_lock:
                        if push_key in self.pushing_products:
                            print(f"âš  å•†å“ {article_num or pid} æ­£åœ¨æ¨é€ä¸­ï¼Œè·³è¿‡é‡å¤æ¨é€")
                            # å›æ»šè®¡æ•°å™¨ï¼ˆä½¿ç”¨è®¡æ•°å™¨é”ï¼‰
                            with self.counter_lock:
                                if group_num == 1:
                                    self.counter_group_1 -= 1
                                    self._save_group_counter(1, self.counter_group_1)
                                elif group_num == 2:
                                    self.counter_group_2 -= 1
                                    self._save_group_counter(2, self.counter_group_2)
                                else:
                                    self.counter_group_3 -= 1
                                    self._save_group_counter(3, self.counter_group_3)
                            continue
                        self.pushing_products.add(push_key)
                    
                    try:
                        print(f"\nğŸ“¦ å¤„ç†å•†å“ {next_no} (ç¾¤ç»„{group_num}, å°ºç æ•°{size_count}):")
                        print(formatted_output)
                        self.write_to_output_file(formatted_output)

                        ok = self.wechat_bot.send_product_to_bot(formatted_output, img_url, group_num)
                        if ok:
                            print(f"âœ“ å•†å“ {next_no} æ¨é€æˆåŠŸ")
                            processed += 1
                            # æŒ‰å°ºç å†·å´ï¼ˆåªå¯¹ kept_map ä¸­çš„å°ºç è¿›è¡Œå†·å´ï¼‰
                            for s in push_sizes_kept:
                                size_key = self._cool_key_size(article_num, s, fallback_id=str(pid))
                                self._mark_cooled_size(size_key)
                            # åªæœ‰æ¨é€æˆåŠŸæ‰æ›´æ–°å†å²æ•°æ®
                            target['detail_data'] = detail_result
                            target['size_price_counts'] = kept_map
                            target['full_size_price_counts'] = curr_full
                            self.detail_processor.update_product_history(target, target['size_price_counts'], curr_full)
                            self.save_initial_data()
                        else:
                            print(f"âœ— å•†å“ {next_no} æ¨é€å¤±è´¥")
                            # æ¨é€å¤±è´¥æ—¶å›æ»šè®¡æ•°å™¨ï¼Œä¿æŒç¼–å·è¿ç»­ï¼ˆä½¿ç”¨è®¡æ•°å™¨é”ï¼‰
                            with self.counter_lock:
                                if group_num == 1:
                                    self.counter_group_1 -= 1
                                    self._save_group_counter(1, self.counter_group_1)
                                elif group_num == 2:
                                    self.counter_group_2 -= 1
                                    self._save_group_counter(2, self.counter_group_2)
                                else:
                                    self.counter_group_3 -= 1
                                    self._save_group_counter(3, self.counter_group_3)
                    finally:
                        # æ¨é€å®Œæˆåä»é›†åˆä¸­ç§»é™¤
                        with self.push_lock:
                            self.pushing_products.discard(push_key)
                time.sleep(1)

        if processed == 0:
            print("  æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å˜åŒ–")

    # ===== ä¸»å¾ªç¯ =====
    def monitor_products(self, check_interval=1):
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] å¼€å§‹ç›‘æ§å•†å“æ•°æ®...")
        if not self.login_with_captcha(self.detail_processor):
            print("ç™»å½•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­ç›‘æ§")
            return
        self.last_login_time = time.time()  # è®°å½•ç™»å½•æ—¶é—´

        while True:
            try:
                self._rollover_if_new_day()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸»åŠ¨åˆ·æ–°ç™»å½•ï¼ˆè¶…è¿‡1å°æ—¶ï¼‰
                if self._should_refresh_login():
                    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] â° ç™»å½•å·²è¶…è¿‡1å°æ—¶ï¼Œä¸»åŠ¨åˆ·æ–°...")
                    self._try_relogin()
                
                t0 = time.time()
                all_new_products = []
                page_num = 1

                first = self.fetch_page(page_num, page_size=500)
                if not first:
                    self.consecutive_failures += 1
                    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] è·å–ç¬¬ä¸€é¡µå¤±è´¥ (è¿ç»­å¤±è´¥ {self.consecutive_failures} æ¬¡)")
                    
                    # è¿ç»­å¤±è´¥å¤šæ¬¡ï¼Œå°è¯•é‡æ–°ç™»å½•
                    if self.consecutive_failures >= self.max_failures_before_relogin:
                        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] âš  è¿ç»­å¤±è´¥ {self.consecutive_failures} æ¬¡ï¼Œå¯èƒ½æ˜¯ç™»å½•è¿‡æœŸ")
                        if self._try_relogin():
                            # é‡æ–°ç™»å½•æˆåŠŸï¼Œç«‹å³é‡è¯•è·å–
                            first = self.fetch_page(page_num, page_size=500)
                            if first:
                                self.consecutive_failures = 0
                                all_new_products.extend(first)
                            else:
                                print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] é‡æ–°ç™»å½•åä»è·å–å¤±è´¥ï¼Œç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥")
                                time.sleep(check_interval)
                                continue
                        else:
                            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥...")
                            time.sleep(check_interval)
                            continue
                    else:
                        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥...")
                        time.sleep(check_interval)
                        continue
                else:
                    self.consecutive_failures = 0  # æˆåŠŸåé‡ç½®å¤±è´¥è®¡æ•°
                    all_new_products.extend(first)

                while True:
                    page_num += 1
                    page_products = self.fetch_page(page_num, page_size=500)
                    if not page_products or len(page_products) == 0:
                        break
                    all_new_products.extend(page_products)

                print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] å…±è·å– {len(all_new_products)} ä¸ªå•†å“")

                new_items, updated_items, _ = self.detect_changes(all_new_products)

                if new_items:
                    print(f"å‘ç° {len(new_items)} ä¸ªæ–°å•†å“")
                    self.process_products_streaming(new_items, "ğŸ†•æ–°å¢")

                if updated_items:
                    print(f"å‘ç° {len(updated_items)} ä¸ªæ›´æ–°å•†å“")
                    updated_products = [i['new'] for i in updated_items]
                    self.process_products_streaming(updated_products, "ğŸ“Œæ›´æ–°")

                self.save_initial_data()
                print(f"\n[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] æœ¬æ¬¡ç›‘æ§è€—æ—¶: {time.time() - t0:.2f}ç§’")
                print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ç­‰å¾… {check_interval} ç§’åè¿›è¡Œä¸‹ä¸€æ¬¡æ£€æŸ¥...")
                time.sleep(check_interval)
            except Exception as e:
                print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ç›‘æ§è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ç­‰å¾… {check_interval} ç§’åé‡è¯•...")
                time.sleep(check_interval)
